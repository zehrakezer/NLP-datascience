{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Solve classification problem(sentiment analysis with NLP) w,th RNN( Deep Learning Language Model) \n",
    "\n",
    "duygu analizi -> bir cümlenin etkiletlenmesi (positif ve negatif)\n",
    "restaurant yorumları değerlendirme\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models import Word2Vec #metin temsili\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset\n",
    "data = {\n",
    "    \"text\": [\n",
    "        \"Yemekler çok lezzetliydi, kesinlikle tekrar geleceğim.\",\n",
    "        \"Servis çok yavaştı, bir daha asla gelmem.\",\n",
    "        \"Garsonlar çok nazikti ve yemekler zamanında geldi.\",\n",
    "        \"Yemek soğuktu ve hiç lezzetli değildi.\",\n",
    "        \"Harika bir atmosfer, yemekler de çok güzeldi.\",\n",
    "        \"Masamız çok kirliydi ve servis berbattı.\",\n",
    "        \"Tatlılar inanılmaz lezzetliydi, çok beğendim.\",\n",
    "        \"Yemeklerin porsiyonları çok küçük ve pahalıydı.\",\n",
    "        \"Çok hoş bir ortamda lezzetli yemekler yedik.\",\n",
    "        \"Servis kalitesi çok kötüydü ve yemekler geç geldi.\",\n",
    "        \"Yemekler taze ve lezzetliydi, sunum çok iyiydi.\",\n",
    "        \"Çalışanlar hiç yardımsever değildi ve ortam rahatsızdı.\",\n",
    "        \"Menüdeki seçenekler çok geniş ve hepsi harikaydı.\",\n",
    "        \"Fiyatlar çok yüksekti, buna değmezdi.\",\n",
    "        \"Müzik çok keyifliydi ve yemekler mükemmeldi.\",\n",
    "        \"Siparişimiz yanlış geldi ve çok uzun süre bekledik.\",\n",
    "        \"Mekan çok temiz ve ferah, yemekler de çok güzeldi.\",\n",
    "        \"Yemekler çok yağlıydı ve tadı kötüydü.\",\n",
    "        \"Aileyle harika bir akşam yemeği geçirdik.\",\n",
    "        \"Hizmet kalitesi rezaletti, tavsiye etmem.\",\n",
    "        \"Tatlılar efsaneydi, bayıldım.\",\n",
    "        \"Servis elemanları çok ilgisizdi ve yemekler kötüydü.\",\n",
    "        \"Ambiyans çok hoştu ve yemekler unutulmazdı.\",\n",
    "        \"Yemekler yanmıştı ve ortam çok gürültülüydü.\",\n",
    "        \"Tatlılar ve kahve gerçekten harikaydı.\",\n",
    "        \"Yemekler çiğdi ve servis çok gecikti.\",\n",
    "        \"Lezzetli yemekler ve samimi bir ortam vardı.\",\n",
    "        \"Çalışanlar kaba ve ilgisizdi.\",\n",
    "        \"Yemeklerin tadı ve sunumu kusursuzdu.\",\n",
    "        \"Fiyat performans açısından çok kötüydü.\",\n",
    "        \"Mekanın dekorasyonu çok şık ve etkileyiciydi.\",\n",
    "        \"Yemeklerin porsiyonları küçüktü ve doyurucu değildi.\",\n",
    "        \"Arkadaşlarla harika vakit geçirdik, yemekler çok iyiydi.\",\n",
    "        \"Yemeklerin tadı tuhaftı, hiç beğenmedim.\",\n",
    "        \"Doğum günü için harika bir mekan, yemekler enfesti.\",\n",
    "        \"Yemek soğuk ve tatsızdı, hayal kırıklığı yaşadım.\",\n",
    "        \"Yemekler mükemmel, çalışanlar çok güler yüzlüydü.\",\n",
    "        \"Restoran çok kalabalıktı, servis çok yavaştı.\",\n",
    "        \"Her şey taze ve çok lezzetliydi.\",\n",
    "        \"Fiyatlar çok yüksek ve hizmet kötüydü.\",\n",
    "        \"Tatlıların sunumu ve tadı çok iyiydi.\",\n",
    "        \"Garsonlar çok ilgisizdi, yemekler de kötüydü.\",\n",
    "        \"Ortam çok sakin ve huzurluydu, yemekler çok iyiydi.\",\n",
    "        \"Yemekler çok tuzluydu ve porsiyonlar küçüktü.\",\n",
    "        \"Şefin özel menüsü gerçekten harikaydı.\",\n",
    "        \"Servis o kadar kötüydü ki bir daha gelmeyi düşünmüyorum.\",\n",
    "        \"Yemeklerin hem lezzeti hem de sunumu muhteşemdi.\",\n",
    "        \"Masamıza hizmet veren garson çok kaba davrandı.\",\n",
    "        \"Mekanın atmosferi ve yemekleri çok etkileyiciydi.\"\n",
    "    ],\n",
    "    \"label\": [\n",
    "        \"positif\",\n",
    "        \"negatif\",\n",
    "        \"positif\",\n",
    "        \"negatif\",\n",
    "        \"positif\",\n",
    "        \"negatif\",\n",
    "        \"positif\",\n",
    "        \"negatif\",\n",
    "        \"positif\",\n",
    "        \"negatif\",\n",
    "        \"positif\",\n",
    "        \"negatif\",\n",
    "        \"positif\",\n",
    "        \"negatif\",\n",
    "        \"positif\",\n",
    "        \"negatif\",\n",
    "        \"positif\",\n",
    "        \"negatif\",\n",
    "        \"positif\",\n",
    "        \"negatif\",\n",
    "        \"positif\",\n",
    "        \"negatif\",\n",
    "        \"positif\",\n",
    "        \"negatif\",\n",
    "        \"positif\",\n",
    "        \"negatif\",\n",
    "        \"positif\",\n",
    "        \"negatif\",\n",
    "        \"positif\",\n",
    "        \"negatif\",\n",
    "        \"positif\",\n",
    "        \"negatif\",\n",
    "        \"positif\",\n",
    "        \"negatif\",\n",
    "        \"positif\",\n",
    "        \"negatif\",\n",
    "        \"positif\",\n",
    "        \"negatif\",\n",
    "        \"positif\",\n",
    "        \"negatif\",\n",
    "        \"positif\",\n",
    "        \"negatif\",\n",
    "        \"positif\",\n",
    "        \"negatif\",\n",
    "        \"positif\",\n",
    "        \"negatif\",\n",
    "        \"positif\",\n",
    "        \"negatif\",\n",
    "        \"positif\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metin temzileme ve preprocessing : tokenşzation, padding, label encoding, train test and split\n",
    "\n",
    "#tokenization\n",
    "tokenizer =Tokenizer()\n",
    "tokenizer.fit_on_texts(df[\"text\"])\n",
    "sequences= tokenizer.texts_to_sequences(df[\"text\"])\n",
    "word_index = tokenizer.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding processes\n",
    "maxlen = max(len(seq) for seq in sequences)\n",
    "X = pad_sequences(sequences,maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test splir\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y ,train_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metin temsiili word embedding : word2vec\n",
    "sentences = [text.split() for text in df[\"text\"]]\n",
    "word2vec_model = Word2Vec(sentences,vector_size=50,window=5,min_count=1)\n",
    "\n",
    "embedding_dim =50\n",
    "embedding_matric = np.zeros((len(word_index)+1, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if word in word2vec_model.wv:\n",
    "        embedding_matric[i] = word2vec_model.wv[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kezer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#modelling, build , train , test rnn modeli\n",
    "model = Sequential()\n",
    "\n",
    "#embedding\n",
    "model.add(Embedding(input_dim= len(word_index)+1,output_dim=embedding_dim,weights=[embedding_matric],input_length=maxlen, trainable= False))\n",
    "\n",
    "#RNN layer\n",
    "model.add(SimpleRNN(50,return_sequences=False))\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model\n",
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 0.6620 - loss: 0.6853 - val_accuracy: 0.4250 - val_loss: 0.7112\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8727 - loss: 0.6196 - val_accuracy: 0.4250 - val_loss: 0.7592\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7894 - loss: 0.5297 - val_accuracy: 0.4250 - val_loss: 0.9562\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8727 - loss: 0.3902 - val_accuracy: 0.4250 - val_loss: 1.3638\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9421 - loss: 0.2475 - val_accuracy: 0.4250 - val_loss: 1.7584\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9630 - loss: 0.1624 - val_accuracy: 0.4250 - val_loss: 1.8284\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8727 - loss: 0.4211 - val_accuracy: 0.4250 - val_loss: 1.5638\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9144 - loss: 0.2776 - val_accuracy: 0.4250 - val_loss: 1.3952\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9630 - loss: 0.1753 - val_accuracy: 0.4250 - val_loss: 1.3162\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9421 - loss: 0.2226 - val_accuracy: 0.4250 - val_loss: 1.1791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x262dd250f90>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "model.fit(X_train,y_train,epochs=10,batch_size=2,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4396 - loss: 1.1506 \n",
      "1.1791213750839233\n",
      "0.42500001192092896\n"
     ]
    }
   ],
   "source": [
    "#evaluate rnn model\n",
    "test_loss, test_accuracy = model.evaluate(X_test,y_test)\n",
    "print(test_loss)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cümle sınıflandırma çalışması\n",
    "def classify_sentence(sentence):\n",
    "\n",
    "    seq = tokenizer.texts_to_sequences([sentence])\n",
    "    padded_seq =pad_sequences(seq,maxlen=maxlen)\n",
    "\n",
    "    prediction=model.predict(padded_seq)\n",
    "    \n",
    "    predicted_class = (prediction>0.5).astype(int)\n",
    "    label = \"positive\" if predicted_class[0][0] == 1 else \"negative\"\n",
    "\n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"restaurant çok temzidi ve yemekler çok güzledi\"\n",
    "\n",
    "classify_sentence(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
